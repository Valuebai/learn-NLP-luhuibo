{
"cells": [
{
"cell_type": "code",
"execution_count": 91,
"metadata": {},
"outputs": [],
"source": [
"import pandas as pd\n",
"text=pd.read_csv('movie_classiffier') \n",
"text.drop(['Unnamed: 0'],axis=1,inplace=True)\n",
"text['train']=text['train'].astype(\"str\")\n",
"\n"
]
},
{
"cell_type": "code",
"execution_count": 52,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"'吴京 意淫 了 脑残 地步 看 恶心 想 吐'"
]
},
"execution_count": 52,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"text.train[0]"
]
},
{
"cell_type": "code",
"execution_count": 4,
"metadata": {},
"outputs": [],
"source": [
"import numpy as np\n",
"np.random.seed(42)\n",
"from sklearn.model_selection import train_test_split\n",
"from sklearn.metrics import roc_auc_score\n",
"\n",
"from tensorflow.keras.models import Model\n",
"from tensorflow.keras.layers import Input, Dense, Embedding, SpatialDropout1D, concatenate , BatchNormalization,Dropout\n",
"from tensorflow.keras.layers import GRU, Bidirectional, GlobalAveragePooling1D, GlobalMaxPooling1D,LSTM\n",
"\n",
"#from tensorflow.keras.preprocessing import text, sequence\n",
"from tensorflow.keras.callbacks import Callback\n",
"from tensorflow.keras import regularizers"
]
},
{
"cell_type": "code",
"execution_count": 16,
"metadata": {},
"outputs": [
{
"name": "stdout",
"output_type": "stream",
"text": [
"（2014）深南法民二初字第280号\n"
]
}
],
"source": [
"\n",
"#判断一段文本中是否包含简体中文\n",
"\n",
"import re\n",
"\n",
"zhmodel = re.compile(u'[一-龥]') #检查中文\n",
"\n",
"#zhmodel = re.compile(u'[^一-龥]') #检查非中文\n",
"\n",
"contents = u'（2014）深南法民二初字第280号'\n",
"\n",
"match = zhmodel.search(contents)\n",
"\n",
"if match:\n",
"\n",
" print(contents)\n",
"\n",
"else:\n",
"\n",
" print(u'没有包含中文')\n"
]
},
{
"cell_type": "code",
"execution_count": 33,
"metadata": {},
"outputs": [],
"source": [
"# 先取5w个试一试 :去掉字母\n",
"length=200000\n",
"def read_data():\n",
" data = {}\n",
" x, y = [], []\n",
" \n",
" \n",
" for i in range(length):\n",
" temp=text.loc[i].train.split()\n",
" index=[]\n",
" for i in range(len(temp)):\n",
" if zhmodel.search(temp[i]):\n",
" index.append(i)\n",
" temp=[temp[i] for i in index]\n",
" x.append(temp)\n",
" y.append(text.loc[i].label)\n",
" x, y = shuffle(x, y)\n",
"# dev_idx =int(length* 0.8 )\n",
"# test_idx =int( length* 0.9 )\n",
"\n",
"\n",
" return x,y"
]
},
{
"cell_type": "code",
"execution_count": 6,
"metadata": {},
"outputs": [],
"source": [
"from sklearn.utils import shuffle"
]
},
{
"cell_type": "code",
"execution_count": 34,
"metadata": {},
"outputs": [],
"source": [
"X_train,y_train =read_data()"
]
},
{
"cell_type": "code",
"execution_count": 92,
"metadata": {},
"outputs": [],
"source": [
"X_train= text.train.fillna(\"fillna\").values"
]
},
{
"cell_type": "code",
"execution_count": 93,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"array(['吴京 意淫 了 脑残 地步 看 恶心 想 吐',\n",
" '首映礼 看 太 恐怖 这个 电影 不讲道理 完全 吴京 实现 这个 小 粉红 英雄 梦 装备 轮番 上场 视 物理 逻辑 不顾 不得不 有钱 真 随意 胡闹',\n",
" '吴京 炒作 水平 不输 冯小刚 但小刚 至少 不会 主旋律 炒作 吴京 人 看 不 舒服 主旋律 主旋律 煽情 煽情 人 觉得 是 大 做作 谎言 家 729 更新 片子 整体 不如 湄公河 行动 整体 不够 流畅 编剧 有毒 台词 尴尬 刻意 做作 主旋律 煽情 显得 不合时宜 又 多余',\n",
" ..., '喜欢 女主角 希腊 雕塑 的 面庞 身体 一部 同志 题材 电影 迷恋 女主角 好像 不 应该 吧',\n",
" '冲着 颜值 可以 看 下去', '除了 主人公 不帅 女主挺 漂亮 之外 唯一 感觉 他 男朋友 真让人 恶心'],\n",
" dtype=object)"
]
},
"execution_count": 93,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"X_train"
]
},
{
"cell_type": "code",
"execution_count": 132,
"metadata": {},
"outputs": [],
"source": [
"y_train = text[['label']].values"
]
},
{
"cell_type": "code",
"execution_count": 133,
"metadata": {},
"outputs": [],
"source": [
"import tensorflow.keras"
]
},
{
"cell_type": "code",
"execution_count": 134,
"metadata": {},
"outputs": [],
"source": [
"y_train=tensorflow.keras.backend.one_hot(y_train,5)"
]
},
{
"cell_type": "code",
"execution_count": 135,
"metadata": {},
"outputs": [],
"source": [
"y_train=tensorflow.keras.backend.reshape(y_train,(-1,5)) "
]
},
{
"cell_type": "code",
"execution_count": 139,
"metadata": {},
"outputs": [],
"source": [
"y_train=y_train.numpy()"
]
},
{
"cell_type": "code",
"execution_count": 136,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"TensorShape([261496, 5])"
]
},
"execution_count": 136,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"y_train.shape\n"
]
},
{
"cell_type": "code",
"execution_count": 57,
"metadata": {},
"outputs": [],
"source": [
"from tensorflow.keras.preprocessing import text, sequence"
]
},
{
"cell_type": "code",
"execution_count": 58,
"metadata": {},
"outputs": [],
"source": [
"tokenizer.fit_on_texts(list(X_train))"
]
},
{
"cell_type": "code",
"execution_count": 59,
"metadata": {
"scrolled": true
},
"outputs": [
{
"data": {
"text/plain": [
"{'看': 1,\n",
" '电影': 2,\n",
" '的': 3,\n",
" '是': 4,\n",
" '啊': 5,\n",
" '一个': 6,\n",
" '故事': 7,\n",
" '我': 8,\n",
" '没有': 9,\n",
" '喜欢': 10,\n",
" '太': 11,\n",
" '剧情': 12,\n",
" '没': 13,\n",
" '吧': 14,\n",
" '不错': 15,\n",
" '得': 16,\n",
" '人': 17,\n",
" '最后': 18,\n",
" '一部': 19,\n",
" '片子': 20,\n",
" '有': 21,\n",
" '不': 22,\n",
" '了': 23,\n",
" '不是': 24,\n",
" '很': 25,\n",
" '觉得': 26,\n",
" '导演': 27,\n",
" '拍': 28,\n",
" '好看': 29,\n",
" '真的': 30,\n",
" '感觉': 31,\n",
" '但是': 32,\n",
" '有点': 33,\n",
" '想': 34,\n",
" '这部': 35,\n",
" '在': 36,\n",
" '都': 37,\n",
" '好': 38,\n",
" '小': 39,\n",
" '真是': 40,\n",
" '这种': 41,\n",
" '片': 42,\n",
" '不过': 43,\n",
" '挺': 44,\n",
" '就': 45,\n",
" '却': 46,\n",
" '爱': 47,\n",
" '也': 48,\n",
" '演技': 49,\n",
" '其实': 50,\n",
" '看到': 51,\n",
" '知道': 52,\n",
" '演员': 53,\n",
" '真': 54,\n",
" '时候': 55,\n",
" '才': 56,\n",
" '完': 57,\n",
" '生活': 58,\n",
" '影片': 59,\n",
" '非常': 60,\n",
" '你': 61,\n",
" '结尾': 62,\n",
" '很多': 63,\n",
" '经典': 64,\n",
" '完全': 65,\n",
" '镜头': 66,\n",
" '能': 67,\n",
" '人物': 68,\n",
" '这': 69,\n",
" '打': 70,\n",
" '死': 71,\n",
" '情节': 72,\n",
" '看过': 73,\n",
" '笑': 74,\n",
" '实在': 75,\n",
" '角色': 76,\n",
" '个': 77,\n",
" '点': 78,\n",
" '不能': 79,\n",
" '现在': 80,\n",
" '逼': 81,\n",
" '爱情': 82,\n",
" '可以': 83,\n",
" '已经': 84,\n",
" '表演': 85,\n",
" '中国': 86,\n",
" '他': 87,\n",
" '结局': 88,\n",
" '还': 89,\n",
" '戏': 90,\n",
" '就是': 91,\n",
" '世界': 92,\n",
" '节奏': 93,\n",
" '只': 94,\n",
" '还是': 95,\n",
" '一直': 96,\n",
" '出来': 97,\n",
" '动作': 98,\n",
" '烂片': 99,\n",
" '演': 100,\n",
" '青春': 101,\n",
" '说': 102,\n",
" '比较': 103,\n",
" '应该': 104,\n",
" '对': 105,\n",
" '可爱': 106,\n",
" '老': 107,\n",
" '多': 108,\n",
" '画面': 109,\n",
" '什么': 110,\n",
" '一点': 111,\n",
" '让': 112,\n",
" '两个': 113,\n",
" '精彩': 114,\n",
" '一起': 115,\n",
" '自己': 116,\n",
" '作品': 117,\n",
" '剧本': 118,\n",
" '风格': 119,\n",
" '被': 120,\n",
" '音乐': 121,\n",
" '配乐': 122,\n",
" '居然': 123,\n",
" '人生': 124,\n",
" '当': 125,\n",
" '可能': 126,\n",
" '最': 127,\n",
" '里面': 128,\n",
" '要': 129,\n",
" '题材': 130,\n",
" '除了': 131,\n",
" '烂': 132,\n",
" '哭': 133,\n",
" '喜剧': 134,\n",
" '感动': 135,\n",
" '特别': 136,\n",
" '不会': 137,\n",
" '真实': 138,\n",
" '观众': 139,\n",
" '美国': 140,\n",
" '像': 141,\n",
" '给': 142,\n",
" '不要': 143,\n",
" '星': 144,\n",
" '会': 145,\n",
" '讲': 146,\n",
" '一种': 147,\n",
" '可惜': 148,\n",
" '以为': 149,\n",
" '这个': 150,\n",
" '搞笑': 151,\n",
" '无聊': 152,\n",
" '男人': 153,\n",
" '出': 154,\n",
" '美': 155,\n",
" '女人': 156,\n",
" '简直': 157,\n",
" '时代': 158,\n",
" '问题': 159,\n",
" '时间': 160,\n",
" '孩子': 161,\n",
" '台词': 162,\n",
" '日本': 163,\n",
" '第一部': 164,\n",
" '那段': 165,\n",
" '一星': 166,\n",
" '这么': 167,\n",
" '之后': 168,\n",
" '场面': 169,\n",
" '东西': 170,\n",
" '简单': 171,\n",
" '编剧': 172,\n",
" '细节': 173,\n",
" '地方': 174,\n",
" '现实': 175,\n",
" '那么': 176,\n",
" '这是': 177,\n",
" '一次': 178,\n",
" '主角': 179,\n",
" '确实': 180,\n",
" '版': 181,\n",
" '只能': 182,\n",
" '一些': 183,\n",
" '每个': 184,\n",
" '所有': 185,\n",
" '三星': 186,\n",
" '那': 187,\n",
" '永远': 188,\n",
" '完美': 189,\n",
" '叙事': 190,\n",
" '起来': 191,\n",
" '特效': 192,\n",
" '无法': 193,\n",
" '希望': 194,\n",
" '把': 195,\n",
" '部分': 196,\n",
" '最好': 197,\n",
" '本片': 198,\n",
" '一定': 199,\n",
" '总是': 200,\n",
" '原来': 201,\n",
" '和': 202,\n",
" '竟然': 203,\n",
" '又': 204,\n",
" '看着': 205,\n",
" '几个': 206,\n",
" '无': 207,\n",
" '值得': 208,\n",
" '男': 209,\n",
" '这样': 210,\n",
" '香港': 211,\n",
" '半': 212,\n",
" '表现': 213,\n",
" '我们': 214,\n",
" '女主': 215,\n",
" '走': 216,\n",
" '需要': 217,\n",
" '成': 218,\n",
" '一下': 219,\n",
" '不如': 220,\n",
" '适合': 221,\n",
" '懂': 222,\n",
" '系列': 223,\n",
" '分钟': 224,\n",
" '情感': 225,\n",
" '大': 226,\n",
" '但': 227,\n",
" '美好': 228,\n",
" '小时': 229,\n",
" '不够': 230,\n",
" '那个': 231,\n",
" '算': 232,\n",
" '剪辑': 233,\n",
" '感情': 234,\n",
" '年代': 235,\n",
" '看看': 236,\n",
" '尤其': 237,\n",
" '整个': 238,\n",
" '终于': 239,\n",
" '英雄': 240,\n",
" '那种': 241,\n",
" '算是': 242,\n",
" '个人': 243,\n",
" '社会': 244,\n",
" '去': 245,\n",
" '女': 246,\n",
" '好像': 247,\n",
" '哈哈哈': 248,\n",
" '尴尬': 249,\n",
" '发现': 250,\n",
" '话': 251,\n",
" '依然': 252,\n",
" '唯一': 253,\n",
" '牛': 254,\n",
" '差': 255,\n",
" '傻': 256,\n",
" '场景': 257,\n",
" '对于': 258,\n",
" '倒': 259,\n",
" '动画': 260,\n",
" '感': 261,\n",
" '亮点': 262,\n",
" '这片': 263,\n",
" '家庭': 264,\n",
" '男主': 265,\n",
" '战争': 266,\n",
" '蛮': 267,\n",
" '出现': 268,\n",
" '人性': 269,\n",
" '没什么': 270,\n",
" '电影院': 271,\n",
" '五星': 272,\n",
" 'ps': 273,\n",
" '之前': 274,\n",
" '后面': 275,\n",
" '来说': 276,\n",
" '一段': 277,\n",
" '摄影': 278,\n",
" '更': 279,\n",
" '真正': 280,\n",
" '印象': 281,\n",
" '类型': 282,\n",
" '本身': 283,\n",
" '绝对': 284,\n",
" '主题': 285,\n",
" '年轻': 286,\n",
" '记得': 287,\n",
" 'nan': 288,\n",
" '期待': 289,\n",
" '找': 290,\n",
" '当年': 291,\n",
" '深刻': 292,\n",
" '一场': 293,\n",
" '女主角': 294,\n",
" '励志': 295,\n",
" '她': 296,\n",
" '令人': 297,\n",
" '生命': 298,\n",
" '事': 299,\n",
" '感人': 300,\n",
" '逻辑': 301,\n",
" '有趣': 302,\n",
" '狗血': 303,\n",
" '成为': 304,\n",
" '温情': 305,\n",
" '到底': 306,\n",
" '搞': 307,\n",
" '的话': 308,\n",
" '失望': 309,\n",
" '想起': 310,\n",
" '整体': 311,\n",
" '大家': 312,\n",
" '本来': 313,\n",
" '充满': 314,\n",
" '幽默': 315,\n",
" '理解': 316,\n",
" '关系': 317,\n",
" '不好': 318,\n",
" '兄弟': 319,\n",
" '成功': 320,\n",
" '之间': 321,\n",
" '式': 322,\n",
" '明白': 323,\n",
" '不同': 324,\n",
" '效果': 325,\n",
" '总': 326,\n",
" '毫无': 327,\n",
" '第一次': 328,\n",
" '很棒': 329,\n",
" '开头': 330,\n",
" '相当': 331,\n",
" '存在': 332,\n",
" '惊喜': 333,\n",
" '回忆': 334,\n",
" '超级': 335,\n",
" '怎么': 336,\n",
" '重要': 337,\n",
" '多少': 338,\n",
" '文艺': 339,\n",
" '吃': 340,\n",
" '方式': 341,\n",
" '真心': 342,\n",
" '吗': 343,\n",
" '带': 344,\n",
" '也许': 345,\n",
" '变成': 346,\n",
" '比': 347,\n",
" '做': 348,\n",
" '垃圾': 349,\n",
" '意义': 350,\n",
" '好莱坞': 351,\n",
" '味道': 352,\n",
" '快': 353,\n",
" '韩国': 354,\n",
" '够': 355,\n",
" '玩': 356,\n",
" '漂亮': 357,\n",
" '历史': 358,\n",
" '全片': 359,\n",
" '一': 360,\n",
" '容易': 361,\n",
" '三个': 362,\n",
" '只是': 363,\n",
" '依旧': 364,\n",
" '有意思': 365,\n",
" '设定': 366,\n",
" '制作': 367,\n",
" '煽情': 368,\n",
" '当然': 369,\n",
" '大概': 370,\n",
" '以后': 371,\n",
" '自然': 372,\n",
" '想象': 373,\n",
" '明显': 374,\n",
" '小时候': 375,\n",
" '名字': 376,\n",
" '梦想': 377,\n",
" '脸': 378,\n",
" '不了': 379,\n",
" '是不是': 380,\n",
" '呵呵': 381,\n",
" '表达': 382,\n",
" '设计': 383,\n",
" '打斗': 384,\n",
" '选择': 385,\n",
" '朋友': 386,\n",
" '突然': 387,\n",
" '清新': 388,\n",
" '基本': 389,\n",
" '四星': 390,\n",
" '国产': 391,\n",
" '越': 392,\n",
" '最佳': 393,\n",
" '不少': 394,\n",
" '直接': 395,\n",
" '主演': 396,\n",
" '以前': 397,\n",
" '为了': 398,\n",
" '片中': 399,\n",
" '开始': 400,\n",
" '好好': 401,\n",
" '意思': 402,\n",
" '改编': 403,\n",
" '动作片': 404,\n",
" '整部': 405,\n",
" '不到': 406,\n",
" '一颗': 407,\n",
" '暴力': 408,\n",
" '男主角': 409,\n",
" '元素': 410,\n",
" '手法': 411,\n",
" '听': 412,\n",
" '不行': 413,\n",
" '越来越': 414,\n",
" '加': 415,\n",
" '最大': 416,\n",
" '震撼': 417,\n",
" '豆瓣': 418,\n",
" '几乎': 419,\n",
" '显得': 420,\n",
" '写': 421,\n",
" '老套': 422,\n",
" '政治': 423,\n",
" '事情': 424,\n",
" '它': 425,\n",
" '别人': 426,\n",
" '大片': 427,\n",
" '台湾': 428,\n",
" '后来': 429,\n",
" '刻意': 430,\n",
" '难看': 431,\n",
" '人类': 432,\n",
" '当时': 433,\n",
" '高潮': 434,\n",
" '残酷': 435,\n",
" '好多': 436,\n",
" '平淡': 437,\n",
" '温暖': 438,\n",
" '黑': 439,\n",
" '套路': 440,\n",
" '老师': 441,\n",
" '棒': 442,\n",
" '情绪': 443,\n",
" '成长': 444,\n",
" '心': 445,\n",
" '相信': 446,\n",
" '还好': 447,\n",
" '出彩': 448,\n",
" '更好': 449,\n",
" '最终': 450,\n",
" '再': 451,\n",
" '过于': 452,\n",
" '所谓': 453,\n",
" '精神': 454,\n",
" '内容': 455,\n",
" '处理': 456,\n",
" '前面': 457,\n",
" '来看': 458,\n",
" '之作': 459,\n",
" '帅': 460,\n",
" '不想': 461,\n",
" '背景': 462,\n",
" '来': 463,\n",
" '样子': 464,\n",
" '过去': 465,\n",
" '些': 466,\n",
" '内心': 467,\n",
" '长': 468,\n",
" '少年': 469,\n",
" '一样': 470,\n",
" '3d': 471,\n",
" '反派': 472,\n",
" '一句': 473,\n",
" '似乎': 474,\n",
" '为': 475,\n",
" '推荐': 476,\n",
" '一群': 477,\n",
" '过程': 478,\n",
" '有人': 479,\n",
" '大叔': 480,\n",
" '笑点': 481,\n",
" '少': 482,\n",
" '拍摄': 483,\n",
" '美丽': 484,\n",
" '努力': 485,\n",
" '记忆': 486,\n",
" '有些': 487,\n",
" '赞': 488,\n",
" '跟': 489,\n",
" '桥段': 490,\n",
" '情怀': 491,\n",
" '想要': 492,\n",
" '恶心': 493,\n",
" '主旋律': 494,\n",
" '接受': 495,\n",
" '水准': 496,\n",
" '此片': 497,\n",
" '莫名其妙': 498,\n",
" '告诉': 499,\n",
" '没想到': 500,\n",
" '他们': 501,\n",
" '致敬': 502,\n",
" '根本': 503,\n",
" '请': 504,\n",
" '幸福': 505,\n",
" '至少': 506,\n",
" '好听': 507,\n",
" '儿子': 508,\n",
" '拖沓': 509,\n",
" '细腻': 510,\n",
" '加上': 511,\n",
" '童年': 512,\n",
" '就算': 513,\n",
" '这次': 514,\n",
" '像是': 515,\n",
" 'b': 516,\n",
" '钱': 517,\n",
" '女性': 518,\n",
" '欢乐': 519,\n",
" '跑': 520,\n",
" '原著': 521,\n",
" '伟大': 522,\n",
" '呢': 523,\n",
" '典型': 524,\n",
" '下去': 525,\n",
" '形象': 526,\n",
" '游戏': 527,\n",
" '影院': 528,\n",
" '结构': 529,\n",
" '警察': 530,\n",
" '父亲': 531,\n",
" '感受': 532,\n",
" '成龙': 533,\n",
" '自由': 534,\n",
" '今天': 535,\n",
" '结束': 536,\n",
" '因为': 537,\n",
" '俗套': 538,\n",
" '港片': 539,\n",
" '难得': 540,\n",
" '是因为': 541,\n",
" '配音': 542,\n",
" '到位': 543,\n",
" '孤独': 544,\n",
" '分': 545,\n",
" '继续': 546,\n",
" '人们': 547,\n",
" '曾经': 548,\n",
" '梦': 549,\n",
" '童话': 550,\n",
" '妈': 551,\n",
" '少女': 552,\n",
" '十分': 553,\n",
" '部': 554,\n",
" '同样': 555,\n",
" '做作': 556,\n",
" '一般': 557,\n",
" '气质': 558,\n",
" '才能': 559,\n",
" '找到': 560,\n",
" '各种': 561,\n",
" '反而': 562,\n",
" '妈妈': 563,\n",
" '水平': 564,\n",
" '可怕': 565,\n",
" '囧': 566,\n",
" '一生': 567,\n",
" '想到': 568,\n",
" '厉害': 569,\n",
" '用': 570,\n",
" '意外': 571,\n",
" '方面': 572,\n",
" '看来': 573,\n",
" '如此': 574,\n",
" '小说': 575,\n",
" '母亲': 576,\n",
" '剧': 577,\n",
" '吸引': 578,\n",
" '发生': 579,\n",
" '国家': 580,\n",
" '行': 581,\n",
" '讨厌': 582,\n",
" '塑造': 583,\n",
" '浪漫': 584,\n",
" '女儿': 585,\n",
" '看得': 586,\n",
" '浪费': 587,\n",
" '观影': 588,\n",
" '或许': 589,\n",
" '悲剧': 590,\n",
" '紧凑': 591,\n",
" '生硬': 592,\n",
" '奥斯卡': 593,\n",
" '从': 594,\n",
" '影响': 595,\n",
" '色彩': 596,\n",
" '过瘾': 597,\n",
" '温馨': 598,\n",
" '爆': 599,\n",
" '今年': 600,\n",
" '鬼': 601,\n",
" '字幕': 602,\n",
" '神': 603,\n",
" '惊艳': 604,\n",
" '么': 605,\n",
" '自我': 606,\n",
" '出色': 607,\n",
" '谁': 608,\n",
" '到': 609,\n",
" '最近': 610,\n",
" '开心': 611,\n",
" '那些': 612,\n",
" '压抑': 613,\n",
" '还要': 614,\n",
" '全程': 615,\n",
" '不管': 616,\n",
" '改变': 617,\n",
" '亲情': 618,\n",
" '肯定': 619,\n",
" '更是': 620,\n",
" '讲述': 621,\n",
" '视角': 622,\n",
" '上映': 623,\n",
" '哎': 624,\n",
" '片尾': 625,\n",
" '男女': 626,\n",
" '黑暗': 627,\n",
" '爸爸': 628,\n",
" '坚持': 629,\n",
" '多么': 630,\n",
" '热血': 631,\n",
" '未来': 632,\n",
" '狗': 633,\n",
" '新意': 634,\n",
" '大师': 635,\n",
" '低': 636,\n",
" '讽刺': 637,\n",
" '青春片': 638,\n",
" '着': 639,\n",
" '中间': 640,\n",
" '刻画': 641,\n",
" '杀': 642,\n",
" '声音': 643,\n",
" '不用': 644,\n",
" '还有': 645,\n",
" '印度': 646,\n",
" '文化': 647,\n",
" '电视剧': 648,\n",
" '混乱': 649,\n",
" '的确': 650,\n",
" '动人': 651,\n",
" '小孩': 652,\n",
" '还行': 653,\n",
" '更加': 654,\n",
" '冲突': 655,\n",
" '属于': 656,\n",
" '两星': 657,\n",
" '语言': 658,\n",
" '难': 659,\n",
" '叫': 660,\n",
" '只有': 661,\n",
" '经历': 662,\n",
" '智商': 663,\n",
" '力量': 664,\n",
" '宗教': 665,\n",
" '一切': 666,\n",
" '心理': 667,\n",
" '轻松': 668,\n",
" '美女': 669,\n",
" '電影': 670,\n",
" '眼睛': 671,\n",
" '黑色幽默': 672,\n",
" '空间': 673,\n",
" '好笑': 674,\n",
" '心里': 675,\n",
" '科幻': 676,\n",
" '大陆': 677,\n",
" '明星': 678,\n",
" '冲着': 679,\n",
" '悬疑': 680,\n",
" '平庸': 681,\n",
" '死亡': 682,\n",
" '续集': 683,\n",
" '见': 684,\n",
" '岁': 685,\n",
" '相比': 686,\n",
" '线': 687,\n",
" '纯粹': 688,\n",
" '忘': 689,\n",
" '造型': 690,\n",
" '必须': 691,\n",
" '技术': 692,\n",
" '评分': 693,\n",
" '别': 694,\n",
" '十足': 695,\n",
" '掉': 696,\n",
" '完整': 697,\n",
" '本': 698,\n",
" '不知': 699,\n",
" '流畅': 700,\n",
" '命运': 701,\n",
" '明明': 702,\n",
" '演得': 703,\n",
" '失去': 704,\n",
" '配角': 705,\n",
" '看起来': 706,\n",
" '主要': 707,\n",
" '拯救': 708,\n",
" '枪战': 709,\n",
" '后半段': 710,\n",
" '强大': 711,\n",
" '能够': 712,\n",
" '事件': 713,\n",
" '略': 714,\n",
" '疯狂': 715,\n",
" '不得不': 716,\n",
" '长镜头': 717,\n",
" '与': 718,\n",
" '虽然': 719,\n",
" '渣': 720,\n",
" '第二部': 721,\n",
" '创意': 722,\n",
" '失败': 723,\n",
" '太多': 724,\n",
" '魅力': 725,\n",
" '艺术': 726,\n",
" '面对': 727,\n",
" '一遍': 728,\n",
" '对白': 729,\n",
" '奇怪': 730,\n",
" '估计': 731,\n",
" '超': 732,\n",
" '毕竟': 733,\n",
" '看不下去': 734,\n",
" '正': 735,\n",
" '在于': 736,\n",
" '西部片': 737,\n",
" '二': 738,\n",
" '功夫': 739,\n",
" '乱': 740,\n",
" '多年': 741,\n",
" '不断': 742,\n",
" '海报': 743,\n",
" '华丽': 744,\n",
" '假': 745,\n",
" '展现': 746,\n",
" '唉': 747,\n",
" '梗': 748,\n",
" '女孩': 749,\n",
" '发展': 750,\n",
" '2': 751,\n",
" '强': 752,\n",
" '每次': 753,\n",
" '城市': 754,\n",
" '思考': 755,\n",
" '得到': 756,\n",
" '哥哥': 757,\n",
" '用心': 758,\n",
" '下来': 759,\n",
" '女神': 760,\n",
" '信仰': 761,\n",
" '夸张': 762,\n",
" '放': 763,\n",
" '广告': 764,\n",
" '传统': 765,\n",
" '弱': 766,\n",
" '睡着': 767,\n",
" '刺激': 768,\n",
" '表情': 769,\n",
" '反正': 770,\n",
" '普通': 771,\n",
" '气氛': 772,\n",
" '认为': 773,\n",
" '无奈': 774,\n",
" '不算': 775,\n",
" '能力': 776,\n",
" '片名': 777,\n",
" '痛苦': 778,\n",
" '复杂': 779,\n",
" '形式': 780,\n",
" '比如': 781,\n",
" '角度': 782,\n",
" '天才': 783,\n",
" '舒服': 784,\n",
" '为什么': 785,\n",
" '瞎': 786,\n",
" '槽': 787,\n",
" '吐': 788,\n",
" '犯罪': 789,\n",
" '黑色': 790,\n",
" '一半': 791,\n",
" '杀手': 792,\n",
" '始终': 793,\n",
" '想象力': 794,\n",
" '恐怖': 795,\n",
" '戏份': 796,\n",
" '动画片': 797,\n",
" '狼': 798,\n",
" '拍出': 799,\n",
" '反转': 800,\n",
" '身上': 801,\n",
" '想法': 802,\n",
" '有种': 803,\n",
" '35': 804,\n",
" '武士': 805,\n",
" '小女孩': 806,\n",
" '法国': 807,\n",
" '一天': 808,\n",
" '前半段': 809,\n",
" '打动': 810,\n",
" '程度': 811,\n",
" '高': 812,\n",
" '矫情': 813,\n",
" '变': 814,\n",
" '比起': 815,\n",
" '年度': 816,\n",
" '不再': 817,\n",
" '治愈': 818,\n",
" '血腥': 819,\n",
" '三': 820,\n",
" '风景': 821,\n",
" '绝望': 822,\n",
" '嗯': 823,\n",
" '仍然': 824,\n",
" '遗憾': 825,\n",
" '足够': 826,\n",
" '长大': 827,\n",
" '却是': 828,\n",
" '原因': 829,\n",
" '超越': 830,\n",
" '美的': 831,\n",
" '铺垫': 832,\n",
" '无比': 833,\n",
" '太过': 834,\n",
" '总体': 835,\n",
" '眼泪': 836,\n",
" '天': 837,\n",
" '性格': 838,\n",
" '很大': 839,\n",
" '评价': 840,\n",
" 'x': 841,\n",
" '尼玛': 842,\n",
" '类似': 843,\n",
" '化': 844,\n",
" '紧张': 845,\n",
" '票房': 846,\n",
" '颜值': 847,\n",
" '变得': 848,\n",
" '模仿': 849,\n",
" '字': 850,\n",
" '间': 851,\n",
" '爆米花': 852,\n",
" '影子': 853,\n",
" '反': 854,\n",
" '啊啊啊': 855,\n",
" '酱油': 856,\n",
" '带来': 857,\n",
" '视觉': 858,\n",
" '彩蛋': 859,\n",
" '矛盾': 860,\n",
" '版本': 861,\n",
" '心中': 862,\n",
" '评论': 863,\n",
" '片段': 864,\n",
" '演绎': 865,\n",
" '演出': 866,\n",
" '商业': 867,\n",
" '三部曲': 868,\n",
" '功力': 869,\n",
" '仍': 870,\n",
" '猜': 871,\n",
" '两部': 872,\n",
" '人心': 873,\n",
" '电视': 874,\n",
" '快乐': 875,\n",
" '影像': 876,\n",
" '家': 877,\n",
" '氛围': 878,\n",
" '哈哈哈哈': 879,\n",
" '难道': 880,\n",
" '看不懂': 881,\n",
" '全部': 882,\n",
" '精致': 883,\n",
" '了解': 884,\n",
" '屎': 885,\n",
" '认真': 886,\n",
" '眼神': 887,\n",
" '悲伤': 888,\n",
" '科恩': 889,\n",
" '商业片': 890,\n",
" '第一': 891,\n",
" '非': 892,\n",
" '亦': 893,\n",
" '說': 894,\n",
" '欣赏': 895,\n",
" '做到': 896,\n",
" '飞机': 897,\n",
" '荒诞': 898,\n",
" '过': 899,\n",
" '穿越': 900,\n",
" '强烈': 901,\n",
" '灵魂': 902,\n",
" '黑帮': 903,\n",
" '标准': 904,\n",
" '追求': 905,\n",
" '值得一看': 906,\n",
" '杨': 907,\n",
" '演戏': 908,\n",
" '差点': 909,\n",
" '再次': 910,\n",
" '吐槽': 911,\n",
" '不可': 912,\n",
" '装': 913,\n",
" '上': 914,\n",
" '路': 915,\n",
" '缺乏': 916,\n",
" '看似': 917,\n",
" '许多': 918,\n",
" '穿': 919,\n",
" '爱情片': 920,\n",
" '熟悉': 921,\n",
" '上帝': 922,\n",
" '片儿': 923,\n",
" '扯': 924,\n",
" '诚意': 925,\n",
" '对话': 926,\n",
" '之外': 927,\n",
" '不太': 928,\n",
" '俩': 929,\n",
" '站': 930,\n",
" '忘记': 931,\n",
" '姑娘': 932,\n",
" '设置': 933,\n",
" '杀人': 934,\n",
" 'tv': 935,\n",
" '没看': 936,\n",
" '影帝': 937,\n",
" '1': 938,\n",
" '跳': 939,\n",
" '回来': 940,\n",
" '彻底': 941,\n",
" '對': 942,\n",
" '回到': 943,\n",
" '不足': 944,\n",
" '活着': 945,\n",
" '般的': 946,\n",
" '买': 947,\n",
" '有着': 948,\n",
" '所以': 949,\n",
" '看点': 950,\n",
" '成本': 951,\n",
" '文艺片': 952,\n",
" '质量': 953,\n",
" '戏剧': 954,\n",
" '国内': 955,\n",
" '粗糙': 956,\n",
" '并': 957,\n",
" '青年': 958,\n",
" '小朋友': 959,\n",
" '结果': 960,\n",
" '如果': 961,\n",
" '解释': 962,\n",
" '出戏': 963,\n",
" '段落': 964,\n",
" '看出': 965,\n",
" '观看': 966,\n",
" '一如既往': 967,\n",
" '冗长': 968,\n",
" '可怜': 969,\n",
" '支持': 970,\n",
" '白': 971,\n",
" '娱乐': 972,\n",
" '90': 973,\n",
" '长得': 974,\n",
" '拍成': 975,\n",
" '类': 976,\n",
" '怪': 977,\n",
" '使': 978,\n",
" '瞬间': 979,\n",
" '复仇': 980,\n",
" '纠结': 981,\n",
" '3': 982,\n",
" '放在': 983,\n",
" '中规中矩': 984,\n",
" '喜剧片': 985,\n",
" '一般般': 986,\n",
" '毁': 987,\n",
" '动物': 988,\n",
" '正常': 989,\n",
" '大战': 990,\n",
" '心情': 991,\n",
" '歌': 992,\n",
" '模式': 993,\n",
" '一幕': 994,\n",
" '浮夸': 995,\n",
" '差不多': 996,\n",
" '状态': 997,\n",
" '仿佛': 998,\n",
" '英国': 999,\n",
" 'bug': 1000,\n",
" ...}"
]
},
"execution_count": 59,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"tokenizer.word_index"
]
},
{
"cell_type": "code",
"execution_count": 60,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"161902"
]
},
"execution_count": 60,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"max_id = len(tokenizer.word_index)\n",
"max_id"
]
},
{
"cell_type": "code",
"execution_count": 61,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"261496"
]
},
"execution_count": 61,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"tokenizer.document_count # whole corpus "
]
},
{
"cell_type": "code",
"execution_count": 94,
"metadata": {},
"outputs": [],
"source": [
"X_train = tokenizer.texts_to_sequences(X_train)"
]
},
{
"cell_type": "code",
"execution_count": 95,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"[29999, 247, 17532]"
]
},
"execution_count": 95,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"max(X_train ) # 30000 以内"
]
},
{
"cell_type": "code",
"execution_count": 66,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"261496"
]
},
"execution_count": 66,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"len(X_train)"
]
},
{
"cell_type": "code",
"execution_count": 68,
"metadata": {},
"outputs": [],
"source": [
"maxlen=50"
]
},
{
"cell_type": "code",
"execution_count": 96,
"metadata": {},
"outputs": [],
"source": [
"x_train = sequence.pad_sequences(X_train, maxlen=maxlen,padding='pre')\n"
]
},
{
"cell_type": "code",
"execution_count": 97,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"array([[ 0, 0, 0, ..., 493, 34, 788],\n",
" [ 0, 0, 0, ..., 54, 2732, 8241],\n",
" [ 0, 0, 0, ..., 10219, 204, 1655],\n",
" ...,\n",
" [ 0, 0, 0, ..., 22, 104, 14],\n",
" [ 0, 0, 0, ..., 83, 1, 525],\n",
" [ 0, 0, 0, ..., 4404, 3722, 493]])"
]
},
"execution_count": 97,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"x_train"
]
},
{
"cell_type": "code",
"execution_count": 74,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"(261496, 50)"
]
},
"execution_count": 74,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"x_train.shape"
]
},
{
"cell_type": "code",
"execution_count": 75,
"metadata": {},
"outputs": [],
"source": [
"word_index = tokenizer.word_index\n",
"nb_words = min(max_features, len(word_index))"
]
},
{
"cell_type": "code",
"execution_count": 76,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"30000"
]
},
"execution_count": 76,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"nb_words"
]
},
{
"cell_type": "code",
"execution_count": 78,
"metadata": {},
"outputs": [],
"source": [
"embed_size=150"
]
},
{
"cell_type": "code",
"execution_count": 79,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"(30000, 150)"
]
},
"execution_count": 79,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"embedding_matrix = np.zeros((nb_words, embed_size))\n",
"embedding_matrix .shape"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": []
},
{
"cell_type": "code",
"execution_count": 81,
"metadata": {},
"outputs": [
{
"name": "stderr",
"output_type": "stream",
"text": [
"\n"
]
}
],
"source": [
"import fasttext\n",
"word_vectors = fasttext.load_model(\"fast2.bin\") # 导入fst模型 "
]
},
{
"cell_type": "code",
"execution_count": 83,
"metadata": {},
"outputs": [],
"source": [
"for word, i in word_index.items():\n",
" if i >= max_features:\n",
" continue\n",
" embedding_vector = word_vectors.get_word_vector(word)\n",
" if embedding_vector is not None: \n",
" embedding_matrix[i] = embedding_vector"
]
},
{
"cell_type": "code",
"execution_count": 85,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"(30000, 150)"
]
},
"execution_count": 85,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"embedding_matrix .shape"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": []
},
{
"cell_type": "code",
"execution_count": 109,
"metadata": {},
"outputs": [],
"source": [
"\n",
"def get_model():\n",
" inp = Input(shape=(maxlen, ))\n",
" x = Embedding(max_features, embed_size, weights=[embedding_matrix])(inp)\n",
" x = SpatialDropout1D(0.2)(x)\n",
" x = Bidirectional(GRU(80, return_sequences=True))(x) #160\n",
" avg_pool = GlobalAveragePooling1D()(x)\n",
" max_pool = GlobalMaxPooling1D()(x)\n",
" conc = concatenate([avg_pool, max_pool])\n",
" outp = Dense(5, activation=\"sigmoid\")(conc)\n",
" print(outp.shape)\n",
" \n",
" model = Model(inputs=inp, outputs=outp)\n",
" model.compile(loss='binary_crossentropy',\n",
" optimizer='adam',\n",
" metrics=['accuracy'])\n",
"\n",
" return model"
]
},
{
"cell_type": "code",
"execution_count": 98,
"metadata": {},
"outputs": [
{
"name": "stderr",
"output_type": "stream",
"text": [
"C:%users\\K\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
" FutureWarning)\n"
]
}
],
"source": [
"X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=233)"
]
},
{
"cell_type": "code",
"execution_count": 99,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"array([ 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
" 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
" 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
" 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 7763,\n",
" 167, 71, 1, 16, 54, 3677])"
]
},
"execution_count": 99,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"X_tra[0]"
]
},
{
"cell_type": "code",
"execution_count": 100,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"50"
]
},
"execution_count": 100,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"maxlen"
]
},
{
"cell_type": "code",
"execution_count": 110,
"metadata": {},
"outputs": [
{
"name": "stdout",
"output_type": "stream",
"text": [
"(None, 5)\n"
]
}
],
"source": [
"model = get_model()"
]
},
{
"cell_type": "code",
"execution_count": 104,
"metadata": {},
"outputs": [
{
"name": "stdout",
"output_type": "stream",
"text": [
"Model: \"model\"\n",
"__________________________________________________________________________________________________\n",
"Layer (type) Output Shape Param # Connected to \n",
"==================================================================================================\n",
"input_1 (InputLayer) [(None, 50)] 0 \n",
"__________________________________________________________________________________________________\n",
"embedding (Embedding) (None, 50, 150) 4500000 input_1[0][0] \n",
"__________________________________________________________________________________________________\n",
"spatial_dropout1d (SpatialDropo (None, 50, 150) 0 embedding[0][0] \n",
"__________________________________________________________________________________________________\n",
"bidirectional (Bidirectional) (None, 50, 160) 111360 spatial_dropout1d[0][0] \n",
"__________________________________________________________________________________________________\n",
"global_average_pooling1d (Globa (None, 160) 0 bidirectional[0][0] \n",
"__________________________________________________________________________________________________\n",
"global_max_pooling1d (GlobalMax (None, 160) 0 bidirectional[0][0] \n",
"__________________________________________________________________________________________________\n",
"concatenate (Concatenate) (None, 320) 0 global_average_pooling1d[0][0] \n",
" global_max_pooling1d[0][0] \n",
"__________________________________________________________________________________________________\n",
"dense (Dense) (None, 6) 1926 concatenate[0][0] \n",
"==================================================================================================\n",
"Total params: 4,613,286\n",
"Trainable params: 4,613,286\n",
"Non-trainable params: 0\n",
"__________________________________________________________________________________________________\n"
]
}
],
"source": [
"model.summary()"
]
},
{
"cell_type": "code",
"execution_count": 105,
"metadata": {},
"outputs": [],
"source": [
"class RocAucEvaluation(Callback):\n",
" def __init__(self, validation_data=(), interval=1):\n",
" super(Callback, self).__init__()\n",
"\n",
" self.interval = interval\n",
" self.X_val, self.y_val = validation_data\n",
"\n",
" def on_epoch_end(self, epoch, logs={}):\n",
" if epoch % self.interval == 0:\n",
" y_pred = self.model.predict(self.X_val, verbose=0)\n",
" score = roc_auc_score(self.y_val, y_pred)\n",
" print(\"\\n ROC-AUC - epoch: %d - score: %.6f \\n\" % (epoch+1, score))"
]
},
{
"cell_type": "code",
"execution_count": 107,
"metadata": {},
"outputs": [],
"source": [
"batch_size = 32\n",
"epochs = 2"
]
},
{
"cell_type": "code",
"execution_count": 145,
"metadata": {},
"outputs": [
{
"name": "stderr",
"output_type": "stream",
"text": [
"C:%users\\K\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
" FutureWarning)\n"
]
},
{
"name": "stdout",
"output_type": "stream",
"text": [
"Train on 248421 samples, validate on 13075 samples\n",
"Epoch 1/2\n",
"248421/248421 [==============================] - 1152s 5ms/sample - loss: 0.2943 - accuracy: 0.8612 - val_loss: 0.3018 - val_accuracy: 0.8569\n",
"Epoch 2/2\n",
" 65344/248421 [======>.......................] - ETA: 14:28 - loss: 0.2715 - accuracy: 0.8753"
]
},
{
"ename": "KeyboardInterrupt",
"evalue": "",
"output_type": "error",
"traceback": [
"\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
"\u001b[1;31mKeyboardInterrupt\u001b[0m Traceback (most recent call last)",
"\u001b[1;32m<ipython-input-145-9bb388cf359f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m 2\u001b[0m \u001b[0mRocAuc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRocAucEvaluation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterval\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mhist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_tra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_tra\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
"\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m 726\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 727\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m 729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 730\u001b[0m def evaluate(self,\n",
"\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m 322\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 323\u001b[0m \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m total_epochs=epochs)\n\u001b[0m\u001b[0;32m 325\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
"\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m 172\u001b[0m batch_end=step * batch_size + current_batch_size)\n\u001b[0;32m 173\u001b[0m \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 174\u001b[1;33m \u001b[0mstep\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m 175\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 176\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
"\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[1;34m(self, type, value, traceback)\u001b[0m\n\u001b[0;32m 86\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 87\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 88\u001b[1;33m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m 89\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 90\u001b[0m \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
"\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mon_batch\u001b[1;34m(self, step, mode, size)\u001b[0m\n\u001b[0;32m 699\u001b[0m self.callbacks._call_batch_hook(\n\u001b[0;32m 700\u001b[0m mode, 'end', step, batch_logs)\n\u001b[1;32m--> 701\u001b[1;33m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
"\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m 758\u001b[0m \u001b[1;31m# will be handled by on_epoch_end.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 759\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 760\u001b[1;33m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog_values\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m 761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 762\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mon_epoch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
"\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras%utils\\generic_utils.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, current, values)\u001b[0m\n\u001b[0;32m 387\u001b[0m \u001b[0mprev_total_width\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_total_width\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 388\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dynamic_display\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 389\u001b[1;33m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\b'\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mprev_total_width\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m 390\u001b[0m \u001b[0msys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstdout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 391\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
"\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m 400\u001b[0m \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 401\u001b[0m \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m 403\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 404\u001b[0m \u001b[1;31m# newlines imply flush in subprocesses\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
"\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m 203\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 204\u001b[0m \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m 206\u001b[0m \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 207\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
"\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m 389\u001b[0m copy_threshold=self.copy_threshold)\n\u001b[0;32m 390\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m 392\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m 393\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
"\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
"\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
"\u001b[1;32mzmq/backend/cython/socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
"\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
"\u001b[1;31mKeyboardInterrupt\u001b[0m: "
]
}
],
"source": [
"X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=233)\n",
"RocAuc = RocAucEvaluation(validation_data=(X_val, y_val), interval=1)\n",
"\n",
"hist = model.fit(X_tra, y_tra, batch_size=batch_size, epochs=epochs, validation_data=(X_val, y_val), verbose=1)\n"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": [
"# 准确率感觉到88 左右。 "
]
},
{
"cell_type": "code",
"execution_count": 140,
"metadata": {},
"outputs": [
{
"name": "stderr",
"output_type": "stream",
"text": [
"C:%users\\K\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
" FutureWarning)\n"
]
}
],
"source": [
"X_tra, X_val, y_tra, y_val = train_test_split(x_train, y_train, train_size=0.95, random_state=233)"
]
},
{
"cell_type": "code",
"execution_count": 112,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"(248421, 50)"
]
},
"execution_count": 112,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"X_tra.shape"
]
},
{
"cell_type": "code",
"execution_count": 143,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"(248421, 5)"
]
},
"execution_count": 143,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"y_tra.shape"
]
},
{
"cell_type": "code",
"execution_count": 142,
"metadata": {},
"outputs": [
{
"data": {
"text/plain": [
"(13075, 5)"
]
},
"execution_count": 142,
"metadata": {},
"output_type": "execute_result"
}
],
"source": [
"y_val.shape"
]
},
{
"cell_type": "code",
"execution_count": null,
"metadata": {},
"outputs": [],
"source": []
}
],
"metadata": {
"kernelspec": {
"display_name": "Python [conda env:anaconda3]",
"language": "python",
"name": "conda-env-anaconda3-py"
},
"language_info": {
"codemirror_mode": {
"name": "ipython",
"version": 3
},
"file_extension": ".py",
"mimetype": "text/x-python",
"name": "python",
"nbconvert_exporter": "python",
"pygments_lexer": "ipython3",
"version": "3.6.5"
}
},
"nbformat": 4,
"nbformat_minor": 2
}
下载|复制|删除当前路径：cells[0].source[0]